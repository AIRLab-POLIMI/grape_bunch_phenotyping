_BASE_: "mask_rcnn_R_101_FPN_3x.yaml"
MODEL:
  ROI_HEADS:
    NUM_CLASSES: 1                # only has one class (bunch)
    BATCH_SIZE_PER_IMAGE: 128     # The "RoIHead batch size". 128 is faster, and good enough for this toy dataset (default: 512)
  RETINANET:
    NUM_CLASSES: 1
  BACKBONE:
    FREEZE_AT: 0                  # default value is 2
DATASETS:
  TRAIN: ("red_globe_2021_07-27_09-06_TRAIN",)
  TEST: ("red_globe_2021_07-27_09-06_TEST",)
INPUT:
  MIN_SIZE_TRAIN: (480, 720)
  MIN_SIZE_TEST: 0                # Set to zero to disable resize in testing.
DATALOADER:
  NUM_WORKERS: 0                  # When the dataset is small, it is suggested to set the NUM_WORKERS to 0 (from PyTorch documentation)
SOLVER:
  IMS_PER_BATCH: 2                # This is the real "batch size" commonly known to deep learning people
  BASE_LR: 0.1                    # possible values: 0.00025                
  MAX_ITER: 2400                  # 48 train images -> 24 batches * 100 epochs = 2400 iterations
  STEPS: [1920, 2160]             # decay learning rate at (0.8 * MAX_ITER) and (0.9 * MAX_ITER) -> only used with the STEP lr scheduler
  WARMUP_ITERS: 70                # 2.5% of MAX_ITER  
  GAMMA: 0.5                      # It is used to control the learning rate decay over time
  CHECKPOINT_PERIOD: 5000         # A model checkpoint will be saved if iteration is a multiple of period 
TEST:
  EVAL_PERIOD: 24                 # 1 evaluation each epoch with 100 epochs. The period (in terms of steps) to evaluate the model during training
  
